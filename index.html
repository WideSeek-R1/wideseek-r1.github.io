<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning">
    <meta name="keywords" content="WideSeek-R1, Multi-Agent, Reinforcement Learning, LLM, Information Seeking, Width Scaling">
    <title>WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via MARL</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script>
        MathJax = { tex: { inlineMath: [['$', '$']], displayMath: [['$$', '$$']] } };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>

    <!-- Global Navigation (visible before scrolling past header) -->
    <nav class="nav-global" id="navGlobal">
        <div class="nav-global-content">
            <div class="nav-global-links">
                <a href="https://vs-bench.github.io/" target="_blank">VS-Bench</a>
                <a href="https://thu-nics.github.io/MARSHAL/" target="_blank">MARSHAL</a>
                <a href="#" class="active" onclick="window.scrollTo({top:0,behavior:'smooth'}); return false;">WideSeek-R1</a>
            </div>
        </div>
    </nav>

    <!-- Sticky Navigation Bar (visible after scrolling past header) -->
    <nav class="nav-sticky-bar" id="navStickyBar">
        <div class="nav-sticky-content">
            <div class="nav-title-wrapper" id="navTitleWrapperSticky">
                <a class="nav-sticky-title" href="#">WideSeek-R1 <i class="fas fa-chevron-down nav-title-chevron"></i></a>
                <div class="nav-dropdown">
                    <div class="nav-dropdown-header">Explore Projects</div>
                    <a class="nav-project-card" href="https://vs-bench.github.io/" target="_blank">
                        <div class="nav-project-card-title">VS-Bench</div>
                        <div class="nav-project-card-desc">Evaluating VLMs for Strategic Abilities in Multi-Agent Environments</div>
                    </a>
                    <a class="nav-project-card" href="https://thu-nics.github.io/MARSHAL/" target="_blank">
                        <div class="nav-project-card-title">MARSHAL</div>
                        <div class="nav-project-card-desc">Incentivizing Multi-Agent Reasoning via Self-Play with Strategic LLMs</div>
                    </a>
                    <a class="nav-project-card" href="#" onclick="window.scrollTo({top:0,behavior:'smooth'}); return false;">
                        <div class="nav-project-card-title active-project">WideSeek-R1</div>
                        <div class="nav-project-card-desc">Exploring Width Scaling for Broad Information Seeking via Multi-Agent RL</div>
                    </a>
                </div>
            </div>
            <div class="nav-sticky-links" id="navStickyLinks">
                <a href="#abstract">Abstract</a>
                <a href="#motivation">Motivation</a>
                <a href="#method">Method</a>
                <a href="#data">Data</a>
                <a href="#results">Results</a>
                <a href="#bibtex">BibTeX</a>
            </div>
            <button class="nav-mobile-toggle" id="navMobileToggle">
                <i class="fas fa-bars"></i>
            </button>
        </div>
    </nav>

    <header>
        <div class="container header-content">
            <h1>WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning</h1>

            <div class="authors">
                <p>
                    <a href="https://nicsefc.ee.tsinghua.edu.cn/people/ZelaiXu" target="_blank">Zelai Xu</a><sup>1*</sup>,
                    Zhexuan Xu<sup>1*</sup>,
                    <a href="https://nicsefc.ee.tsinghua.edu.cn/people/RuizeZhang" target="_blank">Ruize Zhang</a><sup>2*</sup>,
                    Chunyang Zhu<sup>3</sup>,
                    <a href="https://yumiao20071126.github.io" target="_blank">Shi Yu</a><sup>4</sup>,
                    <br>
                    Weilin Liu<sup>3</sup>,
                    Quanlu Zhang<sup>3</sup>,
                    <a href="https://ssr-group.net" target="_blank">Wenbo Ding</a><sup>2</sup>,
                    <a href="https://nicsefc.ee.tsinghua.edu.cn/people/ChaoYu" target="_blank">Chao Yu</a><sup>2&dagger;</sup>,
                    <a href="https://nicsefc.ee.tsinghua.edu.cn/people/YuWang" target="_blank">Yu Wang</a><sup>1&dagger;</sup>
                </p>
                <p class="affiliations">
                    <sup>1</sup>EE, Tsinghua University &nbsp;&nbsp;
                    <sup>2</sup>SIGS, Tsinghua University &nbsp;&nbsp;
                    <sup>3</sup>Infinigence AI &nbsp;&nbsp;
                    <sup>4</sup>IIIS, Tsinghua University
                </p>
                <p class="affiliations" style="color: #333;">
                    <sup>*</sup>Equal Contribution. &nbsp;&nbsp;<sup>&dagger;</sup>Corresponding Authors.
                </p>
            </div>

            <div class="links">
                <a href="https://arxiv.org/abs/2602.04634" class="btn" target="_blank"><i class="fas fa-file-pdf"></i> arXiv</a>
                <a href="https://github.com/RLinf/RLinf/tree/main/examples/wideseek_r1" class="btn" target="_blank"><i class="fab fa-github"></i> Code</a>
                <a href="https://huggingface.co/datasets/RLinf/WideSeek-R1-train-data" class="btn" target="_blank"><i class="fas fa-database"></i> Dataset</a>
                <a href="https://huggingface.co/RLinf/WideSeek-R1-4b" class="btn" target="_blank"><img src="static/images/hf-logo.svg" alt="HuggingFace" class="btn-icon"> Model</a>
            </div>
        </div>
    </header>

    <main class="container">

        <section id="abstract">
            <h2>Abstract</h2>

            <p>
                Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling,
                where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks
                grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work,
                we explore a complementary dimension of <strong>width scaling</strong> with multi-agent systems to address
                broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking
                interactions that fail to parallelize work effectively. To bridge this gap, we propose
                <strong>WideSeek-R1</strong>, a lead-agent&ndash;subagent framework trained via
                <strong>multi-agent reinforcement learning (MARL)</strong> to synergize scalable orchestration and parallel
                execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly
                optimizes the lead agent and parallel subagents on a curated dataset of
                20k broad information-seeking tasks. Extensive experiments show that
                WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is
                comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore,
                WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases,
                highlighting the effectiveness of width scaling.
            </p>

            <div class="method-image" style="margin-top: 30px;">
                <img src="static/images/scaling.png" alt="Depth vs Width Scaling" style="max-width: 60%;">
                <p class="caption">Figure 1: Comparison of depth and width scaling. While depth scaling enhances performance through sequential multi-turn interactions, width scaling orchestrates multi-agent systems for parallel execution. WideSeek-R1 pushes the frontier of width scaling via MARL for synergized orchestration and execution.</p>
            </div>

            <h3>Contributions</h3>
            <ul>
                <li>We introduce <strong>WideSeek-R1</strong>, a multi-agent system trained via MARL to synergize scalable orchestration and parallel execution for broad information seeking.</li>
                <li>We open-source <strong>a large-scale dataset</strong> of 20,000 broad information-seeking tasks, offering a complementary training resource to existing multi-hop datasets.</li>
                <li>We demonstrate the effectiveness of <strong>width scaling</strong> with WideSeek-R1-4B, which achieves comparable performance to DeepSeek-R1-671B and exhibits consistent gains as the number of parallel agents increases.</li>
            </ul>
        </section>

        <section id="motivation">
            <h2>Motivation</h2>

            <p>
                As tasks grow broader, width scaling via multi-agent systems becomes essential, yet
                both single-agent methods and existing multi-agent systems fall short in different ways.
                Broad information seeking, which requires gathering and synthesizing attributes of multiple entities
                into a structured table, serves as an ideal testbed for this challenge.
            </p>

            <h3>Limitations of Single-Agent Methods</h3>
            <p>
                Single-agent methods face two fundamental limitations when tasks grow in breadth.
            </p>
            <ul>
                <li><strong>Context pollution.</strong> As the agent's context accumulates information from previous subtasks,
                    irrelevant content increasingly interferes with reasoning, degrading performance on later subtasks.</li>
                <li><strong>Sequential execution.</strong> A single agent must process independent subtasks one by one,
                    leaving parallelizable work serialized and making the overall process inefficient.</li>
            </ul>
            <p>
                These limitations underscore the necessity of multi-agent systems, which naturally enable context isolation
                and parallel execution for effective width scaling.
            </p>

            <h3>Limitations of Existing Multi-Agent Systems</h3>
            <p>
                Despite their promise, existing multi-agent systems have yet to fully realize the potential of width scaling,
                primarily because few are trained end-to-end to learn scalable orchestration and parallel execution.
            </p>
            <ul>
                <li><strong>Hand-crafted orchestration.</strong> Most prior work relies on manually designed workflows
                    rather than learned agents, hindering flexible and scalable coordination as the number of agents grows.</li>
                <li><strong>Turn-taking execution.</strong> Current systems typically process subtasks one at a time through
                    turn-taking interactions, serializing progress and failing to parallelize independent work.</li>
            </ul>
            <p>
                As a result, the performance of existing multi-agent systems is bottlenecked by limited scalability and
                insufficient parallelization. WideSeek-R1 is designed to address both levels through
                end-to-end multi-agent reinforcement learning.
            </p>
        </section>

        <section id="method">
            <h2>Method</h2>
            <p>
                WideSeek-R1 is a hierarchical lead-agent&ndash;subagent system trained via <strong>end-to-end MARL
                to synergize scalable orchestration and parallel execution</strong> for width scaling.
                The lead agent and subagents share a single LLM but operate with isolated contexts and specialized tools:
                the lead agent focuses on task decomposition and orchestration, while each subagent executes its assigned
                subtask in parallel using external tools to gather information and return findings.
            </p>

            <div class="method-image">
                <img src="static/images/overview.png" alt="WideSeek-R1 Overview">
                <p class="caption">Figure 2. Overview of WideSeek-R1 rollout and training pipeline. <strong>Rollout:</strong> The lead agent coordinates task decomposition while subagents execute parallel subtasks. <strong>Training:</strong> A shared model is trained via GRPO with multi-agent advantage assignment and dual-level advantage reweighting.</p>
            </div>

            <h3>Lead Agent for Scalable Orchestration</h3>
            <p>
                The lead agent is responsible for decomposing a broad task into parallelizable subtasks and delegating
                them to subagents. Unlike existing multi-agent systems that rely on hand-crafted workflows, our lead agent
                is trained to perform <strong>scalable and learnable orchestration</strong>, enabling flexible coordination
                as the number of subagents increases. The only tool available to the lead agent is
                <code>call_subagent</code>, which we intentionally restrict to avoid context pollution.
            </p>

            <h3>Subagents for Parallel Execution</h3>
            <p>
                The subagents are responsible for <strong>parallel information seeking</strong>, enabling width scaling by
                executing multiple subtasks simultaneously. This design addresses the context pollution and sequential
                execution bottlenecks that plague single-agent methods. The subagents are equipped with two tools:
                <code>search</code>, which retrieves relevant snippets and URLs for a given query; and <code>access</code>, which generates a summary from a specific URL.
            </p>

            <h3>Multi-Agent Reinforcement Learning</h3>
            <p>
                We jointly optimize the lead agent and subagents through end-to-end MARL with a shared model, enabling
                the simultaneous learning of orchestration and information-seeking behaviors. Our method builds upon GRPO
                and extends it for multi-agent systems with two key designs:
            </p>
            <ul>
                <li><strong>Multi-Agent Advantage Assignment:</strong> To ensure training stability and prevent reward hacking, we use a verifiable outcome reward for each multi-agent rollout and assign the same advantage to all agents and all tokens.</li>
                <li><strong>Dual-Level Advantage Reweighting:</strong> To better handle multi-agent, multi-turn training of LLMs, we consider both <span style="color:#8B0000;">agent-level</span> and <span style="color:#00008B;">token-level</span> advantage reweighting mechanism within the policy gradient objective.</li>
            </ul>

            <div style="overflow-x: auto; text-align: center; margin: 20px 0;">
$$\mathbb{E}\!\left[\frac{1}{G}\sum_{i=1}^{G} {\color{#8B0000}\frac{1}{N_i}\sum_{a=1}^{N_i}}\ {\color{#00008B}\frac{1}{\sum_{t=1}^{T_{i,a}} |o^t_{i,a}|}\sum_{t=1}^{T_{i,a}}\sum_{j=1}^{|o^t_{i,a}|}}\ \min\!\left(r^{t,j}_{i,a}\hat{A}_i,\ \operatorname{clip}\!\left(r^{t,j}_{i,a},1\!-\!\epsilon_{\mathrm{low}},1\!+\!\epsilon_{\mathrm{high}}\right)\hat{A}_i\right)\right]$$
            </div>
        </section>

        <section id="data">
            <h2>Training Data Construction</h2>
            <p>
                To unlock the potential of width scaling, WideSeek-R1 requires a substantial volume of broad
                information-seeking tasks. We develop a <strong>fully automated data construction pipeline</strong> to
                synthesize high-quality training instances consisting of schema-constrained queries and standardized
                tabular outputs, yielding a large-scale dataset of <strong>20,000 instances</strong>.
            </p>

            <div class="method-image">
                <img src="static/images/data_pipeline.png" alt="Data Pipeline">
                <p class="caption">Figure 3. Overview of the automated data construction pipeline with three stages: Query Generation, Answer Generation, and QA Pair Filtering.</p>
            </div>

            <p style="margin-top: 20px;">Our pipeline operates in three key stages:</p>
            <ol>
                <li><strong>Query Generation:</strong> We extract user intents from HybridQA and refine them into complex,
                    schema-constrained queries that mandate specific table structures and broad coverage.</li>
                <li><strong>Answer Generation:</strong> We prompt the model to generate two responses independently along
                    with the unique column(s), enabling self-consistency verification.</li>
                <li><strong>QA Pair Filtering:</strong> We rigorously screen the data by discarding instances with low
                    consistency or insufficient difficulty, ensuring that only robust and challenging samples remain in
                    the final dataset.</li>
            </ol>
        </section>

        <section id="results">
            <h2>Experiment Results</h2>

            <h3>Main Results on WideSearch</h3>
            <p>
                WideSeek-R1-4B achieves the best results on five out of six metrics among 4B and 8B baselines.
                The multi-agent system consistently outperforms the single-agent variant with an absolute improvement
                of 11.9% in item F1 score, and attains an 8.8% gain over the base Qwen3-4B in the same multi-agent
                setting.
                Notably, <strong>WideSeek-R1-4B achieves performance comparable to single-agent DeepSeek-R1-671B</strong> despite using nearly
                170&times; fewer parameters.
            </p>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th rowspan="2" style="vertical-align: middle;">Setting</th>
                            <th rowspan="2" style="vertical-align: middle;">Model</th>
                            <th colspan="2">Item F1 Score (%)</th>
                            <th colspan="2">Row F1 Score (%)</th>
                            <th colspan="2">Success Rate (%)</th>
                        </tr>
                        <tr>
                            <th>Avg@4</th>
                            <th>Max@4</th>
                            <th>Avg@4</th>
                            <th>Max@4</th>
                            <th>Avg@4</th>
                            <th>Pass@4</th>
                        </tr>
                    </thead>
                    <tbody>
                        <!-- Single Agent Block -->
                        <tr class="setting-row">
                            <td rowspan="5" style="vertical-align: middle; font-weight: bold;">Single<br>Agent</td>
                            <td>SingleSeek-R1-4B</td>
                            <td>28.1</td>
                            <td>39.2</td>
                            <td>6.5</td>
                            <td>12.5</td>
                            <td>0.3</td>
                            <td>1.0</td>
                        </tr>
                        <tr>
                            <td>Qwen3-4B</td>
                            <td>20.1</td>
                            <td>30.2</td>
                            <td>3.0</td>
                            <td>4.8</td>
                            <td>0.0</td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td>Search-R1-7B</td>
                            <td>15.5</td>
                            <td>24.4</td>
                            <td>2.0</td>
                            <td>4.4</td>
                            <td>0.0</td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td>ASearcher-7B</td>
                            <td>16.5</td>
                            <td>26.0</td>
                            <td>2.8</td>
                            <td>5.8</td>
                            <td>0.0</td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td>DeepSeek-R1-671B</td>
                            <td>41.3</td>
                            <td>55.1</td>
                            <td>20.7</td>
                            <td>31.7</td>
                            <td>0.4</td>
                            <td>1.5</td>
                        </tr>
                        <!-- Multi-Agent Block -->
                        <tr class="setting-row">
                            <td rowspan="5" style="vertical-align: middle; font-weight: bold;">Multi-Agent<br>System</td>
                            <td class="highlight-row">WideSeek-R1-4B</td>
                            <td class="highlight-row">40.0</td>
                            <td class="highlight-row">51.8</td>
                            <td class="highlight-row">15.3</td>
                            <td class="highlight-row">24.4</td>
                            <td class="highlight-row">0.4</td>
                            <td class="highlight-row">1.0</td>
                        </tr>
                        <tr>
                            <td>Qwen3-4B</td>
                            <td>31.2</td>
                            <td>42.3</td>
                            <td>8.4</td>
                            <td>15.5</td>
                            <td>0.0</td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td>AgentFlow-7B</td>
                            <td>28.7</td>
                            <td>45.4</td>
                            <td>9.0</td>
                            <td>20.2</td>
                            <td>0.4</td>
                            <td>1.5</td>
                        </tr>
                        <tr>
                            <td>OWL-8B</td>
                            <td>20.2</td>
                            <td>29.3</td>
                            <td>3.1</td>
                            <td>5.8</td>
                            <td>0.0</td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td>MiroFlow-8B</td>
                            <td>23.7</td>
                            <td>37.7</td>
                            <td>5.8</td>
                            <td>12.7</td>
                            <td>0.4</td>
                            <td>1.0</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p class="caption">
                Table 1. Results on the WideSearch benchmark with 100 English and 100 Chinese broad information-seeking tasks requiring tabular output.
            </p>

            <h3>Exploring Width Scaling</h3>
            <p>
                To compare with depth scaling and illustrate the width scaling property of WideSeek-R1, we plot the performance curves with respect to test-time compute, including number of turns for depth scaling and number of agents for width scaling.
            </p>
            <ul>
                <li><strong>Depth Scaling:</strong> Performance initially improves with more turns but quickly plateaus, as the single agent is bottlenecked by its fixed context length.</li>
                <li><strong>Width Scaling:</strong> Performance initially improves with more subagents but begins to decline at ten, as noise from conflicting responses overwhelms the untrained lead agent's ability to aggregate information.</li>
                <li><strong>Width Scaling + MARL:</strong> Performance improves consistently with the number of subagents, pushing the frontier to 40% item F1 score with 10 subagents, demonstrating the effectiveness of MARL in jointly optimizing orchestration and parallel execution.</li>
            </ul>

            <div class="method-image">
                <img src="static/images/exp_scaling.png" alt="Scaling Comparison" style="max-width: 60%;">
                <p class="caption">Figure 4. Comparison of depth and width scaling with respect to (w.r.t.) test-time compute. The blue curve shows depth scaling w.r.t. the number of turns (bottom axis), while the two red curves show width scaling w.r.t. the number of subagents (top axis).</p>
            </div>

            <h3>Ablation Studies</h3>
            <p>
                We conduct ablation studies to dissect the key components of our framework, aiming to answer two
                primary questions: (1) Is the joint optimization of both the lead agent and subagents necessary for
                optimal performance? (2) How does our constructed dataset impact the model's overall capability?
            </p>

            <div class="ablation-figures">
                <div class="ablation-item">
                    <img src="static/images/ablation_agent.png" alt="Agent Ablation">
                    <p class="caption">Figure 5. Ablation on lead agent and subagents.</p>
                </div>
                <div class="ablation-item">
                    <img src="static/images/ablation_data.png" alt="Data Ablation">
                    <p class="caption">Figure 6. Ablation on training data composition.</p>
                </div>
            </div>

            <p>
                <strong>Lead Agent and Subagents (Left).</strong> We evaluate four settings by assigning either
                WideSeek-R1-4B or Qwen3-4B to each role. The best performance is achieved when both roles use
                WideSeek-R1-4B, and upgrading either role alone yields comparable gains, confirming that MARL
                effectively enhances both orchestration and subtask execution. The further gains from combining both
                roles highlight the synergy between these capabilities and validate the importance of end-to-end training.
            </p>
            <p>
                <strong>Training Data (Right).</strong> We compare models trained on wide-only, deep-only, and hybrid
                datasets of equal size. The model trained on the hybrid dataset consistently outperforms those trained on either wide-only or deep-only dataset across all
                metrics, indicating that wide and deep data provide complementary benefits: wide data helps the system
                learn effective orchestration, while deep data enhances information-seeking and subtask execution.
            </p>
            <h3>Standard QA Benchmarks</h3>
            <p>
                To assess the versatility of WideSeek-R1 beyond broad information seeking, we evaluate it on seven
                standard open-domain QA benchmarks spanning three single-hop datasets and four
                multi-hop datasets. WideSeek-R1-4B achieves an
                average score of 59.0%, outperforming its backbone multi-agent Qwen3-4B by 7.7% and surpassing
                larger multi-agent systems like OWL-8B and MiroFlow-8B, validating that our MARL framework enhances
                width scaling without compromising general tool-use capabilities.
            </p>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th rowspan="2" style="vertical-align: middle;">Setting</th>
                            <th rowspan="2" style="vertical-align: middle;">Model</th>
                            <th rowspan="2" style="vertical-align: middle;">Average</th>
                            <th colspan="3">Single-Hop</th>
                            <th colspan="4">Multi-Hop</th>
                        </tr>
                        <tr>
                            <th>NQ</th>
                            <th>TriviaQA</th>
                            <th>PopQA</th>
                            <th>2Wiki</th>
                            <th>HotpotQA</th>
                            <th>Bamboogle</th>
                            <th>MuSiQue</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="setting-row">
                            <td rowspan="4" style="vertical-align: middle; font-weight: bold;">Single<br>Agent</td>
                            <td>SingleSeek-R1-4B</td>
                            <td>57.0</td><td>58.8</td><td>78.3</td><td>48.0</td><td>70.9</td><td>62.1</td><td>54.6</td><td>26.5</td>
                        </tr>
                        <tr>
                            <td>Qwen3-4B</td>
                            <td>48.3</td><td>48.5</td><td>68.7</td><td>43.0</td><td>58.9</td><td>51.4</td><td>48.2</td><td>19.2</td>
                        </tr>
                        <tr>
                            <td>Search-R1-7B</td>
                            <td>55.4</td><td>49.9</td><td>78.0</td><td>55.7</td><td>58.1</td><td>60.8</td><td>58.4</td><td>27.1</td>
                        </tr>
                        <tr>
                            <td>ASearcher-7B</td>
                            <td>61.0</td><td>54.5</td><td>79.3</td><td>55.9</td><td>77.6</td><td>67.6</td><td>60.0</td><td>32.6</td>
                        </tr>
                        <tr class="setting-row">
                            <td rowspan="5" style="vertical-align: middle; font-weight: bold;">Multi-Agent<br>System</td>
                            <td class="highlight-row">WideSeek-R1-4B</td>
                            <td class="highlight-row">59.0</td><td class="highlight-row">56.1</td><td class="highlight-row">78.5</td><td class="highlight-row">48.5</td><td class="highlight-row">75.0</td><td class="highlight-row">64.2</td><td class="highlight-row">61.8</td><td class="highlight-row">28.9</td>
                        </tr>
                        <tr>
                            <td>Qwen3-4B</td>
                            <td>51.3</td><td>49.6</td><td>70.7</td><td>44.9</td><td>65.0</td><td>54.3</td><td>52.6</td><td>21.7</td>
                        </tr>
                        <tr>
                            <td>AgentFlow-7B</td>
                            <td>61.0</td><td>58.5</td><td>87.0</td><td>52.5</td><td>77.2</td><td>57.0</td><td>69.6</td><td>25.3</td>
                        </tr>
                        <tr>
                            <td>OWL-8B</td>
                            <td>57.2</td><td>64.0</td><td>74.2</td><td>52.2</td><td>62.6</td><td>61.0</td><td>55.8</td><td>30.4</td>
                        </tr>
                        <tr>
                            <td>MiroFlow-8B</td>
                            <td>50.0</td><td>50.9</td><td>73.1</td><td>42.8</td><td>58.6</td><td>52.4</td><td>50.8</td><td>21.3</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p class="caption">
                Table 2. Results on standard QA benchmarks including three single-hop and four multi-hop benchmarks.
            </p>
        </section>

        <section id="bibtex">
            <h2>BibTeX</h2>
            <div class="citation-block">
                <button class="copy-btn" id="copyBibtex" title="Copy BibTeX">
                    <i class="fas fa-clone"></i>
                </button>
                <pre><code id="bibtex-code">@article{xu2026wideseek,
  title={WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning},
  author={Xu, Zelai and Xu, Zhexuan and Zhang, Ruize and Zhu, Chunyang and Yu, Shi and Liu, Weilin and Zhang, Quanlu and Ding, Wenbo and Yu, Chao and Wang, Yu},
  journal={arXiv preprint arXiv:2602.04634},
  year={2026},
}</code></pre>
            </div>
        </section>

    </main>

    <footer>
        <p>&copy; 2026 WideSeek-R1 Project, licensed under
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" style="color: inherit;">CC BY-SA 4.0</a>.
        </p>
    </footer>

    <!-- Back-to-top button -->
    <button class="scroll-top" id="scrollTop">
        <i class="fas fa-chevron-up"></i>
    </button>

    <script>
    (function () {
        var navGlobal = document.getElementById('navGlobal');
        var navBar = document.getElementById('navStickyBar');
        var scrollTopBtn = document.getElementById('scrollTop');
        var header = document.querySelector('header');
        var sectionIds = ['abstract', 'motivation', 'method', 'data', 'results', 'bibtex'];

        function updateNav() {
            var heroBottom = header ? header.offsetTop + header.offsetHeight : 300;
            if (window.scrollY > heroBottom - 60) {
                navBar.classList.add('visible');
                navGlobal.classList.add('hidden');
            } else {
                navBar.classList.remove('visible');
                navGlobal.classList.remove('hidden');
            }

            // Highlight active section in TOC
            var links = document.querySelectorAll('.nav-sticky-links a');
            var current = '';
            sectionIds.forEach(function (id) {
                var el = document.getElementById(id);
                if (el && window.scrollY >= el.offsetTop - 80) {
                    current = id;
                }
            });
            links.forEach(function (link) {
                link.classList.toggle('active', link.getAttribute('href') === '#' + current);
            });
        }

        function updateScrollTop() {
            scrollTopBtn.classList.toggle('visible', window.scrollY > 500);
        }

        window.addEventListener('scroll', updateNav, { passive: true });
        window.addEventListener('scroll', updateScrollTop, { passive: true });

        // Close dropdown when clicking outside
        document.addEventListener('click', function (e) {
            document.querySelectorAll('.nav-title-wrapper').forEach(function (wrapper) {
                if (!wrapper.contains(e.target)) {
                    wrapper.classList.remove('open');
                }
            });
        });

        // Mobile toggle
        var mobileToggle = document.getElementById('navMobileToggle');
        var navLinks = document.getElementById('navStickyLinks');
        if (mobileToggle && navLinks) {
            mobileToggle.addEventListener('click', function () {
                this.classList.toggle('active');
                navLinks.classList.toggle('mobile-open');
            });
            navLinks.querySelectorAll('a').forEach(function (link) {
                link.addEventListener('click', function () {
                    mobileToggle.classList.remove('active');
                    navLinks.classList.remove('mobile-open');
                });
            });
        }

        // Scroll to top
        if (scrollTopBtn) {
            scrollTopBtn.addEventListener('click', function () {
                window.scrollTo({ top: 0, behavior: 'smooth' });
            });
        }

        // Initial state
        updateNav();
        updateScrollTop();

        // Copy BibTeX button
        var copyBtn = document.getElementById('copyBibtex');
        if (copyBtn) {
            copyBtn.addEventListener('click', function () {
                var text = document.getElementById('bibtex-code').innerText;
                navigator.clipboard.writeText(text).then(function () {
                    copyBtn.innerHTML = '<i class="fas fa-check"></i>';
                    setTimeout(function () {
                        copyBtn.innerHTML = '<i class="fas fa-clone"></i>';
                    }, 2000);
                });
            });
        }
    })();
    </script>

</body>

</html>
